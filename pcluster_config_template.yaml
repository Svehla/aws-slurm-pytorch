Region: {{REGION}}
Image:
  Os: ubuntu2004 
  # mmm....
  # Cluster status   : CREATE_FAILED => needs to be created via pcluster CLI
  # custom AMI applied to Head + compute nodes?
  # https://aws.amazon.com/blogs/hpc/custom-amis-with-parallelcluster-3/
  # CustomAmi: ami-0bbe1f8dbd94bdf07

  # I need to try 
  # 1. EC2 => it works
  CustomAmi: ami-0c078394f90de4df5
  # 2. EC2 wrapped by pcluster build-image => it works
  # CustomAmi: ami-0339a9a18eda12cb3
  # 3. try to do a build made by IMAGE_CONFIG.yaml
  # CustomAmi: ????


# inspiration:
# https://github.com/pytorch/examples/blob/main/distributed/ddp-tutorial-series/slurm/config.yaml.template
# by default computeNode + headNode has shared home (~) directory so i do not need to mount shared file
# when i use fsx with this conf, it charge me about 2$ per few hours... i should optimize it somehow

# Too expensive!!!
# SharedStorage:
#   - MountDir: /shared
#     Name: shared-fs
#     StorageType: FsxLustre
#     FsxLustreSettings:
#       StorageCapacity: 1200
#       DeploymentType: SCRATCH_1
#       StorageType: SSD

# TODO: use EBS instead
SharedStorage:
  - MountDir: /shared
    Name: shared-ebs
    StorageType: Ebs
    EbsSettings:
      VolumeType: gp2
      Size: 200


# t2.micro is too small to install pytorch (it throws out of memory) 
# TODO: make somehow bigger space of head node
# t2.small => $0.023 (1cpu, 2ram)
# t2.medium => $0.046 (2cpu, 4ram)
# c5.large => $0.085 (2cpu, 4ram)
HeadNode:
  # TODO: put cheaper instance here, all compute heavy tasks are made by compute nodes right now
  # c5.large
  InstanceType: t2.medium
  Networking:
    SubnetId: {{SUBNET_ID}}
  Ssh:
    KeyName: {{SSH_HEAD_NODE_KEY_PAIR_NAME}}
Scheduling:
  Scheduler: slurm
  SlurmQueues:
  # TODO: add support for spot instance
  - Name: pytorch-queue-1-gpu
    ComputeResources:
    - Name: my-small-gpu-node
      # ami-0abcd1234efgh5678 
      # ImageId: {{IMAGE_ID}}
      Instances:
      - InstanceType: g4dn.xlarge
      MinCount: 0
      MaxCount: 4
    Networking:
      SubnetIds:
      - {{SUBNET_ID}}

  - Name: pytorch-queue-2-gpu
    ComputeResources:
    - Name: my-2-gpu-node
      Instances:
      - InstanceType: g3.8xlarge
      MinCount: 0
      MaxCount: 4
    Networking:
      SubnetIds:
      - {{SUBNET_ID}}

  - Name: pytorch-queue-4-gpu
    ComputeResources:
    - Name: my-large-gpu-node
      Instances:
      - InstanceType: g4dn.12xlarge
      MinCount: 0
      MaxCount: 2
    Networking:
      SubnetIds:
      - {{SUBNET_ID}}